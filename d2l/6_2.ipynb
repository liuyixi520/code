{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 填充和步幅\n",
    "- 填充和步幅，是卷积神经网络里除了卷积核大小之外的另外两个重要的超参数\n",
    "- 填充是为了解决卷积核的边界问题，步幅是为了解决卷积核的滑动问题·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充的例子\n",
    "- 记原始图片的大小为 $[n_h, n_w]$ 卷积核的大小为 $[k_h, k_w]$ （一般会取奇数）\n",
    "- 此时只考虑步幅最一般的情况，即 $[1, 1]$\n",
    "- 那么每次经过卷积运算之后，输出的图片大小为 $[n_h - k_h + 1, n_w - k_w + 1]$\n",
    "- 那么此时原始图片缩小的长度为 $[k_h-1, k_w-1]$\n",
    "- 如果我们此时我们在上下左右分别填充 $[(k_h-1)/2, (k_h-1)/2, (k_w-1)/2, (k_w-1)/w]$\n",
    "- 那么我们就能保证在经过卷积运算之后的图片大小仍然是 $[n_h, n_w]$\n",
    "- 这就是为什么要引进填充的原因，因为卷积核的边界问题\n",
    "## 步幅的例子\n",
    "- 记原始图片的大小为 $[n_h, n_w]$ 卷积核的大小为 $[k_h, k_w]$ （一般会取奇数）\n",
    "- 此时如果不考虑填充，只考虑步幅为 $[2, 2]$\n",
    "- 直观的感受，当步幅增加后，经过卷积核运算之后，数据会缩减的更快\n",
    "- 那么每次经过卷积运算之后，输出的图片大小为 $[\\lfloor n_h - k_h + 2 \\rfloor /2, \\lfloor n_w - k_w + 2 \\rfloor /2]$\n",
    "## 更一般的情况\n",
    "- 记原始图片的大小为 $[n_h, n_w]$ 卷积核的大小为 $[k_h, k_w]$ （一般会取奇数）,步幅为 $[s_h, s_w]$，填充为 $[p_h, p_w]$\n",
    "- 经过卷积核运算之后，输出的图片大小为 $[\\lfloor n_h - k_h + p_h + s_h \\rfloor /s_h, \\lfloor n_w - k_w + + p_w + s_w \\rfloor /s_w]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里转一下的原因在于nn.Conv2d的输入是(N, C, H, W)\n",
    "    # 前两个参数分别代表输入通道数量、输出通道数量\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Y在返回的时候也保留了前两个维度，图片数量和通道数，所以返回的时候我们是不关心的，要把他去掉\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 上下左右分别填充一行，卷积核的大小是3x3，所以此时缩小的是2x2，刚好抵消掉，图片大小不变\n",
    "conv2d = nn.Conv2d(1, 1, 3, padding=1)\n",
    "X = torch.randn(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充不同的高度和宽度\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 扩大步幅，增大缩小的比例\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 3), padding=(1, 1), stride=(2, 2))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1021d31412234ebea20baf61e8fdbc8c22153a59dde70b52bcafccce89619e30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
