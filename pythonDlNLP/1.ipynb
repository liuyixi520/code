{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络的复习\n",
    "## 数学和Python的复习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Y = [[10 11 12]\n",
      " [13 14 15]\n",
      " [16 17 18]]\n",
      "X + Y = [[11 13 15]\n",
      " [17 19 21]\n",
      " [23 25 27]]\n",
      "X - Y = [[-9 -9 -9]\n",
      " [-9 -9 -9]\n",
      " [-9 -9 -9]]\n",
      "X * Y = [[ 10  22  36]\n",
      " [ 52  70  90]\n",
      " [112 136 162]]\n",
      "X / Y = [[0.1        0.18181818 0.25      ]\n",
      " [0.30769231 0.35714286 0.4       ]\n",
      " [0.4375     0.47058824 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "# 矩阵的四则运算\n",
    "import numpy as np\n",
    "X = np.arange(1,10).reshape(3,3)\n",
    "Y = np.arange(10,19).reshape(3,3)\n",
    "print(f'X = {X}')\n",
    "print(f'Y = {Y}')\n",
    "print(f'X + Y = {X+Y}')\n",
    "print(f'X - Y = {X-Y}')\n",
    "print(f'X * Y = {X*Y}')\n",
    "print(f'X / Y = {X/Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Y = [1 2 3]\n",
      "X + Y = [[ 2  4  6]\n",
      " [ 5  7  9]\n",
      " [ 8 10 12]]\n"
     ]
    }
   ],
   "source": [
    "# numpy的广播性质，不够的直接补全\n",
    "X = np.arange(1,10).reshape(3,3)\n",
    "Y = np.array([1,2,3])\n",
    "print(f'X = {X}')\n",
    "print(f'Y = {Y}')\n",
    "print(f'X + Y = {X+Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 = [1 2 3]\n",
      "v2 = [4 5 6]\n",
      "m1 = [[1 2 3]\n",
      " [4 5 6]]\n",
      "m2 = [[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]]\n",
      "v1.dot(v2) = 32\n",
      "m1.dot(m2) = [[ 58  64]\n",
      " [139 154]]\n"
     ]
    }
   ],
   "source": [
    "# 向量的内机和矩阵的内积\n",
    "v1 = np.arange(1, 4)\n",
    "v2 = np.arange(4, 7)\n",
    "m1 = np.arange(1, 7).reshape(2,3)\n",
    "m2 = np.arange(7, 13).reshape(3,2)\n",
    "print(f'v1 = {v1}')\n",
    "print(f'v2 = {v2}')\n",
    "print(f'm1 = {m1}')\n",
    "print(f'm2 = {m2}')\n",
    "print(f'v1.dot(v2) = {v1.dot(v2)}')\n",
    "print(f'm1.dot(m2) = {m1.dot(m2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.dot(v2) = 32\n",
      "v1.dot(v2.T) = 32\n",
      "v1.dot(m1.T) = [14 32]\n"
     ]
    }
   ],
   "source": [
    "# 一些深入理解，试错\n",
    "# 两个向量做点积操作时，np对行向量、列向量不敏感，只是简单的做点积\n",
    "# 只要保证两个向量的长度一样，最后输出一个标量就可以了\n",
    "print(f'v1.dot(v2) = {v1.dot(v2)}')\n",
    "print(f'v1.dot(v2.T) = {v1.dot(v2.T)}')\n",
    "# 向量和矩阵做点积时，np是把向量当成一个行向量处理的\n",
    "# 会报错，v1.dim[0] != m1.dim[0]\n",
    "# print(f'v1.dot(m1) = {v1.dot(m1)}')\n",
    "print(f'v1.dot(m1.T) = {v1.dot(m1.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的推理\n",
    "- 神经网络推理：用的是矩阵的乘法，是一个正向传播的过程，为的是描绘了从输入到输出的过程\n",
    "- 神经网络学习：用的是导数或梯度，是一个反向传播的过程，为的是求解出来最优的参数，即寻找最好的假设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[ 0.62653337 -0.552979  ]\n",
      " [-0.9520352   0.23762954]\n",
      " [-0.09752724  0.25475613]\n",
      " [-0.51042304 -0.25760947]\n",
      " [ 0.53388914 -1.44918337]\n",
      " [ 0.95601421  1.0933019 ]\n",
      " [-0.29354884 -0.0517866 ]\n",
      " [-0.15412597 -0.47939242]\n",
      " [-0.48251533  1.98678073]\n",
      " [-1.12764586 -0.54508709]]\n",
      "W1 = [[ 0.36607087  0.59791697  0.95424091  1.16920601]\n",
      " [-1.12623964 -1.67963229 -0.25207239  1.18594923]]\n",
      "b1 = [-0.26488781 -0.06951758  0.53048374 -0.32671743]\n",
      "y = [[ 0.58725468  1.23389874  1.26773825 -0.24997587]\n",
      " [-0.88102797 -1.03788582 -0.43788705 -1.15802615]\n",
      " [-0.58750614 -0.55572738  0.37320227 -0.13861903]\n",
      " [-0.16160882  0.05798101  0.10835342 -1.22901887]\n",
      " [ 1.56268121  2.68379897  1.40524172 -1.42114894]\n",
      " [-1.1462388  -1.33424563  1.16716038  2.08766068]\n",
      " [-0.31402337 -0.15805297  0.26342139 -0.73135278]\n",
      " [ 0.21860191  0.64353088  0.50425203 -1.07545751]\n",
      " [-2.67911384 -3.69508273 -0.43076471  1.46534381]\n",
      " [-0.06378742  0.1717897  -0.40816067 -2.29161336]]\n"
     ]
    }
   ],
   "source": [
    "# 模仿神经网络的前线传播\n",
    "x = np.random.randn(10,2) # 10个样本，2个特征\n",
    "W1 = np.random.randn(2, 4) # 4个神经元，每个神经元上有两个权重参数\n",
    "b1 = np.random.randn(4) # 4个偏置\n",
    "y = x.dot(W1) + b1\n",
    "print(f'x = {x}')\n",
    "print(f'W1 = {W1}')\n",
    "print(f'b1 = {b1}')\n",
    "print(f'y = {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (10, 2)\n",
      "W1.shape = (2, 4)\n",
      "b1.shape = (4,)\n",
      "W2.shape = (4, 2)\n",
      "b2.shape = (2,)\n",
      "h.shape = (10, 4)\n",
      "a.shape = (10, 4)\n",
      "y.shape = (10, 2)\n"
     ]
    }
   ],
   "source": [
    "# 带激活函数的前线传播\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "X = np.random.randn(10,2)\n",
    "W1 = np.random.randn(2,4)\n",
    "b1 = np.random.randn(4)\n",
    "W2 = np.random.randn(4,2)\n",
    "b2 = np.random.randn(2)\n",
    "h = np.dot(X, W1) + b1\n",
    "a = sigmoid(h)\n",
    "y = np.dot(a, W2) + b2\n",
    "print(f'X.shape = {X.shape}')\n",
    "print(f'W1.shape = {W1.shape}')\n",
    "print(f'b1.shape = {b1.shape}')\n",
    "print(f'W2.shape = {W2.shape}')\n",
    "print(f'b2.shape = {b2.shape}')\n",
    "print(f'h.shape = {h.shape}')\n",
    "print(f'a.shape = {a.shape}')\n",
    "print(f'y.shape = {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的学习\n",
    "- 损失函数\n",
    "- 连式法则：误差反向传递\n",
    "### 计算图\n",
    "- 使用计算图是辅助理解反向传播的重要方法\n",
    "- 加法算子的反向传播会原封不动的向下游传递梯度\n",
    "- 乘法算子的反向传播会将信号翻转后向下游传递梯度\n",
    "- 分支算子的反向传播会将信合合并起来向下游传递梯度\n",
    "- 矩阵乘法的算子会将信号翻转转置后向下游传递梯度，比较麻烦，需要结合矩阵大小想象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用神经网络解决实际问题\n",
    "### 螺旋状数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./dataset/spiral.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (300, 2)\n",
      "t.shape = (300, 3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.spiral import load_data\n",
    "\n",
    "x, t = load_data()\n",
    "print(f'x.shape = {x.shape}')\n",
    "print(f't.shape = {t.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 100\n",
    "CLS_NUM = 3\n",
    "markers = ['o', 'x', '^']\n",
    "for i in range(CLS_NUM):\n",
    "    plt.scatter(x[N*i:N*(i+1), 0], x[N*i:N*(i+1), 1], marker=markers[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from common.layers import Affine, Sigmoid, SoftmaxWithLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        # 初始化权重偏置\n",
    "        W1 = 0.01 * np.random.randn(I, H)\n",
    "        b1 = np.zeros(H)\n",
    "        W2 = 0.01 * np.random.randn(H, O)\n",
    "        b2 = np.zeros(O)\n",
    "        # 初始化层\n",
    "        self.layers = [Affine(W1, b1), Sigmoid(), Affine(W2, b2)]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        # 将所有的参数和梯度放到一个列表中\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            # 列表的 += -> append\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    # 推理\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    # 前项传播\n",
    "    def forward(self, x, t):\n",
    "        # 预测\n",
    "        score = self.predict(x)\n",
    "        # 计算损失\n",
    "        loss = self.loss_layer.forward(score, t)\n",
    "        return loss\n",
    "    # 后项传播\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common/optimizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import spiral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 10 / 10 | loss 1.125606\n",
      "| epoch 2 |  iter 10 / 10 | loss 1.125520\n",
      "| epoch 3 |  iter 10 / 10 | loss 1.116261\n",
      "| epoch 4 |  iter 10 / 10 | loss 1.116287\n",
      "| epoch 5 |  iter 10 / 10 | loss 1.112300\n",
      "| epoch 6 |  iter 10 / 10 | loss 1.138464\n",
      "| epoch 7 |  iter 10 / 10 | loss 1.159096\n",
      "| epoch 8 |  iter 10 / 10 | loss 1.108632\n",
      "| epoch 9 |  iter 10 / 10 | loss 1.117331\n",
      "| epoch 10 |  iter 10 / 10 | loss 1.128796\n",
      "| epoch 11 |  iter 10 / 10 | loss 1.116844\n",
      "| epoch 12 |  iter 10 / 10 | loss 1.108339\n",
      "| epoch 13 |  iter 10 / 10 | loss 1.087615\n",
      "| epoch 14 |  iter 10 / 10 | loss 1.076681\n",
      "| epoch 15 |  iter 10 / 10 | loss 1.044238\n",
      "| epoch 16 |  iter 10 / 10 | loss 1.034578\n",
      "| epoch 17 |  iter 10 / 10 | loss 0.957293\n",
      "| epoch 18 |  iter 10 / 10 | loss 0.918385\n",
      "| epoch 19 |  iter 10 / 10 | loss 0.924149\n",
      "| epoch 20 |  iter 10 / 10 | loss 0.868514\n",
      "| epoch 21 |  iter 10 / 10 | loss 0.849381\n",
      "| epoch 22 |  iter 10 / 10 | loss 0.817163\n",
      "| epoch 23 |  iter 10 / 10 | loss 0.792441\n",
      "| epoch 24 |  iter 10 / 10 | loss 0.782665\n",
      "| epoch 25 |  iter 10 / 10 | loss 0.823543\n",
      "| epoch 26 |  iter 10 / 10 | loss 0.775457\n",
      "| epoch 27 |  iter 10 / 10 | loss 0.755786\n",
      "| epoch 28 |  iter 10 / 10 | loss 0.764477\n",
      "| epoch 29 |  iter 10 / 10 | loss 0.783490\n",
      "| epoch 30 |  iter 10 / 10 | loss 0.750790\n",
      "| epoch 31 |  iter 10 / 10 | loss 0.777307\n",
      "| epoch 32 |  iter 10 / 10 | loss 0.765084\n",
      "| epoch 33 |  iter 10 / 10 | loss 0.772790\n",
      "| epoch 34 |  iter 10 / 10 | loss 0.781940\n",
      "| epoch 35 |  iter 10 / 10 | loss 0.747980\n",
      "| epoch 36 |  iter 10 / 10 | loss 0.744992\n",
      "| epoch 37 |  iter 10 / 10 | loss 0.756035\n",
      "| epoch 38 |  iter 10 / 10 | loss 0.762137\n",
      "| epoch 39 |  iter 10 / 10 | loss 0.730890\n",
      "| epoch 40 |  iter 10 / 10 | loss 0.753027\n",
      "| epoch 41 |  iter 10 / 10 | loss 0.759842\n",
      "| epoch 42 |  iter 10 / 10 | loss 0.759444\n",
      "| epoch 43 |  iter 10 / 10 | loss 0.760925\n",
      "| epoch 44 |  iter 10 / 10 | loss 0.738524\n",
      "| epoch 45 |  iter 10 / 10 | loss 0.748329\n",
      "| epoch 46 |  iter 10 / 10 | loss 0.732212\n",
      "| epoch 47 |  iter 10 / 10 | loss 0.722695\n",
      "| epoch 48 |  iter 10 / 10 | loss 0.732945\n",
      "| epoch 49 |  iter 10 / 10 | loss 0.722859\n",
      "| epoch 50 |  iter 10 / 10 | loss 0.722511\n",
      "| epoch 51 |  iter 10 / 10 | loss 0.715136\n",
      "| epoch 52 |  iter 10 / 10 | loss 0.719546\n",
      "| epoch 53 |  iter 10 / 10 | loss 0.737519\n",
      "| epoch 54 |  iter 10 / 10 | loss 0.736158\n",
      "| epoch 55 |  iter 10 / 10 | loss 0.722465\n",
      "| epoch 56 |  iter 10 / 10 | loss 0.718289\n",
      "| epoch 57 |  iter 10 / 10 | loss 0.707484\n",
      "| epoch 58 |  iter 10 / 10 | loss 0.700404\n",
      "| epoch 59 |  iter 10 / 10 | loss 0.717282\n",
      "| epoch 60 |  iter 10 / 10 | loss 0.701417\n",
      "| epoch 61 |  iter 10 / 10 | loss 0.713980\n",
      "| epoch 62 |  iter 10 / 10 | loss 0.715839\n",
      "| epoch 63 |  iter 10 / 10 | loss 0.702415\n",
      "| epoch 64 |  iter 10 / 10 | loss 0.714766\n",
      "| epoch 65 |  iter 10 / 10 | loss 0.725839\n",
      "| epoch 66 |  iter 10 / 10 | loss 0.699195\n",
      "| epoch 67 |  iter 10 / 10 | loss 0.714904\n",
      "| epoch 68 |  iter 10 / 10 | loss 0.692379\n",
      "| epoch 69 |  iter 10 / 10 | loss 0.695072\n",
      "| epoch 70 |  iter 10 / 10 | loss 0.705174\n",
      "| epoch 71 |  iter 10 / 10 | loss 0.681889\n",
      "| epoch 72 |  iter 10 / 10 | loss 0.693108\n",
      "| epoch 73 |  iter 10 / 10 | loss 0.667884\n",
      "| epoch 74 |  iter 10 / 10 | loss 0.679569\n",
      "| epoch 75 |  iter 10 / 10 | loss 0.669692\n",
      "| epoch 76 |  iter 10 / 10 | loss 0.660103\n",
      "| epoch 77 |  iter 10 / 10 | loss 0.694894\n",
      "| epoch 78 |  iter 10 / 10 | loss 0.644871\n",
      "| epoch 79 |  iter 10 / 10 | loss 0.679797\n",
      "| epoch 80 |  iter 10 / 10 | loss 0.638993\n",
      "| epoch 81 |  iter 10 / 10 | loss 0.635210\n",
      "| epoch 82 |  iter 10 / 10 | loss 0.664218\n",
      "| epoch 83 |  iter 10 / 10 | loss 0.619476\n",
      "| epoch 84 |  iter 10 / 10 | loss 0.622967\n",
      "| epoch 85 |  iter 10 / 10 | loss 0.612511\n",
      "| epoch 86 |  iter 10 / 10 | loss 0.597191\n",
      "| epoch 87 |  iter 10 / 10 | loss 0.598820\n",
      "| epoch 88 |  iter 10 / 10 | loss 0.608389\n",
      "| epoch 89 |  iter 10 / 10 | loss 0.588113\n",
      "| epoch 90 |  iter 10 / 10 | loss 0.577325\n",
      "| epoch 91 |  iter 10 / 10 | loss 0.557383\n",
      "| epoch 92 |  iter 10 / 10 | loss 0.560459\n",
      "| epoch 93 |  iter 10 / 10 | loss 0.544899\n",
      "| epoch 94 |  iter 10 / 10 | loss 0.528602\n",
      "| epoch 95 |  iter 10 / 10 | loss 0.529931\n",
      "| epoch 96 |  iter 10 / 10 | loss 0.516307\n",
      "| epoch 97 |  iter 10 / 10 | loss 0.512431\n",
      "| epoch 98 |  iter 10 / 10 | loss 0.501644\n",
      "| epoch 99 |  iter 10 / 10 | loss 0.484474\n",
      "| epoch 100 |  iter 10 / 10 | loss 0.480006\n",
      "| epoch 101 |  iter 10 / 10 | loss 0.460993\n",
      "| epoch 102 |  iter 10 / 10 | loss 0.454022\n",
      "| epoch 103 |  iter 10 / 10 | loss 0.453571\n",
      "| epoch 104 |  iter 10 / 10 | loss 0.442993\n",
      "| epoch 105 |  iter 10 / 10 | loss 0.436155\n",
      "| epoch 106 |  iter 10 / 10 | loss 0.410493\n",
      "| epoch 107 |  iter 10 / 10 | loss 0.403164\n",
      "| epoch 108 |  iter 10 / 10 | loss 0.407611\n",
      "| epoch 109 |  iter 10 / 10 | loss 0.403624\n",
      "| epoch 110 |  iter 10 / 10 | loss 0.399515\n",
      "| epoch 111 |  iter 10 / 10 | loss 0.379217\n",
      "| epoch 112 |  iter 10 / 10 | loss 0.375047\n",
      "| epoch 113 |  iter 10 / 10 | loss 0.362295\n",
      "| epoch 114 |  iter 10 / 10 | loss 0.367571\n",
      "| epoch 115 |  iter 10 / 10 | loss 0.346165\n",
      "| epoch 116 |  iter 10 / 10 | loss 0.344898\n",
      "| epoch 117 |  iter 10 / 10 | loss 0.335289\n",
      "| epoch 118 |  iter 10 / 10 | loss 0.338074\n",
      "| epoch 119 |  iter 10 / 10 | loss 0.328344\n",
      "| epoch 120 |  iter 10 / 10 | loss 0.335197\n",
      "| epoch 121 |  iter 10 / 10 | loss 0.315839\n",
      "| epoch 122 |  iter 10 / 10 | loss 0.317407\n",
      "| epoch 123 |  iter 10 / 10 | loss 0.305581\n",
      "| epoch 124 |  iter 10 / 10 | loss 0.313067\n",
      "| epoch 125 |  iter 10 / 10 | loss 0.300182\n",
      "| epoch 126 |  iter 10 / 10 | loss 0.298742\n",
      "| epoch 127 |  iter 10 / 10 | loss 0.283803\n",
      "| epoch 128 |  iter 10 / 10 | loss 0.281184\n",
      "| epoch 129 |  iter 10 / 10 | loss 0.281834\n",
      "| epoch 130 |  iter 10 / 10 | loss 0.277715\n",
      "| epoch 131 |  iter 10 / 10 | loss 0.272388\n",
      "| epoch 132 |  iter 10 / 10 | loss 0.267077\n",
      "| epoch 133 |  iter 10 / 10 | loss 0.270945\n",
      "| epoch 134 |  iter 10 / 10 | loss 0.270572\n",
      "| epoch 135 |  iter 10 / 10 | loss 0.270309\n",
      "| epoch 136 |  iter 10 / 10 | loss 0.264373\n",
      "| epoch 137 |  iter 10 / 10 | loss 0.263783\n",
      "| epoch 138 |  iter 10 / 10 | loss 0.256050\n",
      "| epoch 139 |  iter 10 / 10 | loss 0.252154\n",
      "| epoch 140 |  iter 10 / 10 | loss 0.242911\n",
      "| epoch 141 |  iter 10 / 10 | loss 0.239455\n",
      "| epoch 142 |  iter 10 / 10 | loss 0.245423\n",
      "| epoch 143 |  iter 10 / 10 | loss 0.236675\n",
      "| epoch 144 |  iter 10 / 10 | loss 0.240319\n",
      "| epoch 145 |  iter 10 / 10 | loss 0.233613\n",
      "| epoch 146 |  iter 10 / 10 | loss 0.236510\n",
      "| epoch 147 |  iter 10 / 10 | loss 0.230254\n",
      "| epoch 148 |  iter 10 / 10 | loss 0.229329\n",
      "| epoch 149 |  iter 10 / 10 | loss 0.224017\n",
      "| epoch 150 |  iter 10 / 10 | loss 0.223947\n",
      "| epoch 151 |  iter 10 / 10 | loss 0.223108\n",
      "| epoch 152 |  iter 10 / 10 | loss 0.222641\n",
      "| epoch 153 |  iter 10 / 10 | loss 0.216977\n",
      "| epoch 154 |  iter 10 / 10 | loss 0.217560\n",
      "| epoch 155 |  iter 10 / 10 | loss 0.215071\n",
      "| epoch 156 |  iter 10 / 10 | loss 0.208358\n",
      "| epoch 157 |  iter 10 / 10 | loss 0.209135\n",
      "| epoch 158 |  iter 10 / 10 | loss 0.204805\n",
      "| epoch 159 |  iter 10 / 10 | loss 0.208607\n",
      "| epoch 160 |  iter 10 / 10 | loss 0.198156\n",
      "| epoch 161 |  iter 10 / 10 | loss 0.204356\n",
      "| epoch 162 |  iter 10 / 10 | loss 0.197240\n",
      "| epoch 163 |  iter 10 / 10 | loss 0.211989\n",
      "| epoch 164 |  iter 10 / 10 | loss 0.199901\n",
      "| epoch 165 |  iter 10 / 10 | loss 0.196708\n",
      "| epoch 166 |  iter 10 / 10 | loss 0.194937\n",
      "| epoch 167 |  iter 10 / 10 | loss 0.188613\n",
      "| epoch 168 |  iter 10 / 10 | loss 0.187136\n",
      "| epoch 169 |  iter 10 / 10 | loss 0.185926\n",
      "| epoch 170 |  iter 10 / 10 | loss 0.188374\n",
      "| epoch 171 |  iter 10 / 10 | loss 0.189995\n",
      "| epoch 172 |  iter 10 / 10 | loss 0.182731\n",
      "| epoch 173 |  iter 10 / 10 | loss 0.184414\n",
      "| epoch 174 |  iter 10 / 10 | loss 0.183306\n",
      "| epoch 175 |  iter 10 / 10 | loss 0.180235\n",
      "| epoch 176 |  iter 10 / 10 | loss 0.175111\n",
      "| epoch 177 |  iter 10 / 10 | loss 0.177674\n",
      "| epoch 178 |  iter 10 / 10 | loss 0.176687\n",
      "| epoch 179 |  iter 10 / 10 | loss 0.172938\n",
      "| epoch 180 |  iter 10 / 10 | loss 0.173286\n",
      "| epoch 181 |  iter 10 / 10 | loss 0.176538\n",
      "| epoch 182 |  iter 10 / 10 | loss 0.172826\n",
      "| epoch 183 |  iter 10 / 10 | loss 0.176269\n",
      "| epoch 184 |  iter 10 / 10 | loss 0.174346\n",
      "| epoch 185 |  iter 10 / 10 | loss 0.169491\n",
      "| epoch 186 |  iter 10 / 10 | loss 0.177554\n",
      "| epoch 187 |  iter 10 / 10 | loss 0.172857\n",
      "| epoch 188 |  iter 10 / 10 | loss 0.166485\n",
      "| epoch 189 |  iter 10 / 10 | loss 0.165942\n",
      "| epoch 190 |  iter 10 / 10 | loss 0.169311\n",
      "| epoch 191 |  iter 10 / 10 | loss 0.163011\n",
      "| epoch 192 |  iter 10 / 10 | loss 0.169589\n",
      "| epoch 193 |  iter 10 / 10 | loss 0.161907\n",
      "| epoch 194 |  iter 10 / 10 | loss 0.159395\n",
      "| epoch 195 |  iter 10 / 10 | loss 0.162860\n",
      "| epoch 196 |  iter 10 / 10 | loss 0.161242\n",
      "| epoch 197 |  iter 10 / 10 | loss 0.163649\n",
      "| epoch 198 |  iter 10 / 10 | loss 0.152768\n",
      "| epoch 199 |  iter 10 / 10 | loss 0.159703\n",
      "| epoch 200 |  iter 10 / 10 | loss 0.157478\n",
      "| epoch 201 |  iter 10 / 10 | loss 0.154677\n",
      "| epoch 202 |  iter 10 / 10 | loss 0.156938\n",
      "| epoch 203 |  iter 10 / 10 | loss 0.155477\n",
      "| epoch 204 |  iter 10 / 10 | loss 0.153948\n",
      "| epoch 205 |  iter 10 / 10 | loss 0.157584\n",
      "| epoch 206 |  iter 10 / 10 | loss 0.153485\n",
      "| epoch 207 |  iter 10 / 10 | loss 0.154463\n",
      "| epoch 208 |  iter 10 / 10 | loss 0.147680\n",
      "| epoch 209 |  iter 10 / 10 | loss 0.151415\n",
      "| epoch 210 |  iter 10 / 10 | loss 0.149356\n",
      "| epoch 211 |  iter 10 / 10 | loss 0.151705\n",
      "| epoch 212 |  iter 10 / 10 | loss 0.147559\n",
      "| epoch 213 |  iter 10 / 10 | loss 0.147851\n",
      "| epoch 214 |  iter 10 / 10 | loss 0.145160\n",
      "| epoch 215 |  iter 10 / 10 | loss 0.146784\n",
      "| epoch 216 |  iter 10 / 10 | loss 0.143884\n",
      "| epoch 217 |  iter 10 / 10 | loss 0.142598\n",
      "| epoch 218 |  iter 10 / 10 | loss 0.145552\n",
      "| epoch 219 |  iter 10 / 10 | loss 0.139224\n",
      "| epoch 220 |  iter 10 / 10 | loss 0.137309\n",
      "| epoch 221 |  iter 10 / 10 | loss 0.144106\n",
      "| epoch 222 |  iter 10 / 10 | loss 0.140508\n",
      "| epoch 223 |  iter 10 / 10 | loss 0.142250\n",
      "| epoch 224 |  iter 10 / 10 | loss 0.142546\n",
      "| epoch 225 |  iter 10 / 10 | loss 0.136672\n",
      "| epoch 226 |  iter 10 / 10 | loss 0.136590\n",
      "| epoch 227 |  iter 10 / 10 | loss 0.142517\n",
      "| epoch 228 |  iter 10 / 10 | loss 0.136087\n",
      "| epoch 229 |  iter 10 / 10 | loss 0.129100\n",
      "| epoch 230 |  iter 10 / 10 | loss 0.138831\n",
      "| epoch 231 |  iter 10 / 10 | loss 0.131423\n",
      "| epoch 232 |  iter 10 / 10 | loss 0.135950\n",
      "| epoch 233 |  iter 10 / 10 | loss 0.134293\n",
      "| epoch 234 |  iter 10 / 10 | loss 0.131441\n",
      "| epoch 235 |  iter 10 / 10 | loss 0.131483\n",
      "| epoch 236 |  iter 10 / 10 | loss 0.128607\n",
      "| epoch 237 |  iter 10 / 10 | loss 0.135392\n",
      "| epoch 238 |  iter 10 / 10 | loss 0.132231\n",
      "| epoch 239 |  iter 10 / 10 | loss 0.131346\n",
      "| epoch 240 |  iter 10 / 10 | loss 0.137816\n",
      "| epoch 241 |  iter 10 / 10 | loss 0.133673\n",
      "| epoch 242 |  iter 10 / 10 | loss 0.128605\n",
      "| epoch 243 |  iter 10 / 10 | loss 0.127750\n",
      "| epoch 244 |  iter 10 / 10 | loss 0.130022\n",
      "| epoch 245 |  iter 10 / 10 | loss 0.131460\n",
      "| epoch 246 |  iter 10 / 10 | loss 0.127966\n",
      "| epoch 247 |  iter 10 / 10 | loss 0.126434\n",
      "| epoch 248 |  iter 10 / 10 | loss 0.132010\n",
      "| epoch 249 |  iter 10 / 10 | loss 0.127790\n",
      "| epoch 250 |  iter 10 / 10 | loss 0.130403\n",
      "| epoch 251 |  iter 10 / 10 | loss 0.133485\n",
      "| epoch 252 |  iter 10 / 10 | loss 0.124540\n",
      "| epoch 253 |  iter 10 / 10 | loss 0.121327\n",
      "| epoch 254 |  iter 10 / 10 | loss 0.122860\n",
      "| epoch 255 |  iter 10 / 10 | loss 0.122670\n",
      "| epoch 256 |  iter 10 / 10 | loss 0.123125\n",
      "| epoch 257 |  iter 10 / 10 | loss 0.121278\n",
      "| epoch 258 |  iter 10 / 10 | loss 0.124673\n",
      "| epoch 259 |  iter 10 / 10 | loss 0.131957\n",
      "| epoch 260 |  iter 10 / 10 | loss 0.120267\n",
      "| epoch 261 |  iter 10 / 10 | loss 0.125003\n",
      "| epoch 262 |  iter 10 / 10 | loss 0.120621\n",
      "| epoch 263 |  iter 10 / 10 | loss 0.118108\n",
      "| epoch 264 |  iter 10 / 10 | loss 0.126816\n",
      "| epoch 265 |  iter 10 / 10 | loss 0.118074\n",
      "| epoch 266 |  iter 10 / 10 | loss 0.120140\n",
      "| epoch 267 |  iter 10 / 10 | loss 0.119930\n",
      "| epoch 268 |  iter 10 / 10 | loss 0.117325\n",
      "| epoch 269 |  iter 10 / 10 | loss 0.113605\n",
      "| epoch 270 |  iter 10 / 10 | loss 0.118883\n",
      "| epoch 271 |  iter 10 / 10 | loss 0.116335\n",
      "| epoch 272 |  iter 10 / 10 | loss 0.118254\n",
      "| epoch 273 |  iter 10 / 10 | loss 0.116237\n",
      "| epoch 274 |  iter 10 / 10 | loss 0.123225\n",
      "| epoch 275 |  iter 10 / 10 | loss 0.113263\n",
      "| epoch 276 |  iter 10 / 10 | loss 0.115801\n",
      "| epoch 277 |  iter 10 / 10 | loss 0.124185\n",
      "| epoch 278 |  iter 10 / 10 | loss 0.112895\n",
      "| epoch 279 |  iter 10 / 10 | loss 0.110776\n",
      "| epoch 280 |  iter 10 / 10 | loss 0.114312\n",
      "| epoch 281 |  iter 10 / 10 | loss 0.114274\n",
      "| epoch 282 |  iter 10 / 10 | loss 0.117315\n",
      "| epoch 283 |  iter 10 / 10 | loss 0.111740\n",
      "| epoch 284 |  iter 10 / 10 | loss 0.113824\n",
      "| epoch 285 |  iter 10 / 10 | loss 0.113546\n",
      "| epoch 286 |  iter 10 / 10 | loss 0.110828\n",
      "| epoch 287 |  iter 10 / 10 | loss 0.112356\n",
      "| epoch 288 |  iter 10 / 10 | loss 0.116989\n",
      "| epoch 289 |  iter 10 / 10 | loss 0.113948\n",
      "| epoch 290 |  iter 10 / 10 | loss 0.114727\n",
      "| epoch 291 |  iter 10 / 10 | loss 0.111952\n",
      "| epoch 292 |  iter 10 / 10 | loss 0.112527\n",
      "| epoch 293 |  iter 10 / 10 | loss 0.110190\n",
      "| epoch 294 |  iter 10 / 10 | loss 0.111479\n",
      "| epoch 295 |  iter 10 / 10 | loss 0.115783\n",
      "| epoch 296 |  iter 10 / 10 | loss 0.110223\n",
      "| epoch 297 |  iter 10 / 10 | loss 0.119668\n",
      "| epoch 298 |  iter 10 / 10 | loss 0.111603\n",
      "| epoch 299 |  iter 10 / 10 | loss 0.106687\n",
      "| epoch 300 |  iter 10 / 10 | loss 0.108550\n"
     ]
    }
   ],
   "source": [
    "# 设定超参数\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0\n",
    "\n",
    "# 读入数据\n",
    "x, t = spiral.load_data()\n",
    "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
    "optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "# 学习用的变量\n",
    "data_size = len(x)\n",
    "max_iters = data_size//batch_size\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    idx = np.random.permutation(data_size)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "        # 前项传播\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        # 后项传播\n",
    "        model.backward()\n",
    "        # 更新参数\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        if (iters+1) % 10 == 0:\n",
    "            avg_loss = total_loss / loss_count\n",
    "            print(f'| epoch {epoch+1:d} |  iter {iters+1:d} / {max_iters:d} | loss {avg_loss:.6f}')\n",
    "            loss_list.append(avg_loss)\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1021d31412234ebea20baf61e8fdbc8c22153a59dde70b52bcafccce89619e30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
