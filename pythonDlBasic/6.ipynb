{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 与学习相关的技巧\n",
    "## 参数的更新策略\n",
    "- SGD: 找到梯度，顺着梯度的方向更新权重，最后让损失函数最小\n",
    "- Momentum: 动量\n",
    "- AdaGrad: 动量的一种，每次更新权重时，都加上上一次的梯度\n",
    "- Adam: AdaGrad + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始值的设定\n",
    "- 不可以将所有的权重设置为相同的值，会导致“权重均一化”的情况出现\n",
    "- 一般使用Xavier初始化权重"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1021d31412234ebea20baf61e8fdbc8c22153a59dde70b52bcafccce89619e30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
